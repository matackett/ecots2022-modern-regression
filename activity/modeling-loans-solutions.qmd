---
title: "Modeling loans - Solutions"
subtitle: "eCOTS 2022 - Modernizing the undergraduate regression analysis course"
editor: visual
execute:
  freeze: auto
---

# Demo

```{r}
#| label: load-pkgs
#| message: false
 
library(tidyverse)
library(tidymodels)
library(knitr)
library(openintro)
```

## Introduction

In today's workshop, we will explore using the **tidymodels** framework for modeling along with the tidyverse framework for data wrangling and visualization.
We will start with some exploratory data analysis, walk through how to create the key components of a predictive model (models, recipes, and workflows), and how to perform cross-validation.
Throughout we will be using the [`loans_full_schema`](http://openintrostat.github.io/openintro/reference/loans_full_schema.html) dataset from the **openintro** package[^1] and featured in the OpenIntro textbooks[^2]
.

[^1]: Mine Çetinkaya-Rundel, David Diez, Andrew Bray, Albert Y.
    Kim, Ben Baumer, Chester Ismay, Nick Paterno and
 Christopher Barr (2022).
    openintro: Data Sets and
 Supplemental Functions from 'OpenIntro' Textbooks and Labs.
    R package version 2.3.0.
    <https://CRAN.R-project.org/package=openintro>.

[^2]: Mine Çetinkaya-Rundel and Johanna Hardin.
    2021.
    OpenIntro::Introduction to Modern Statistics.
    [https://openintro-ims.netlify.app](https://openintro-ims.netlify.app/).

The exercises below are drawn from an exam review.
Students would have already completed readings, some assignments, and labs prior to attempting these questions.

You may notice some code below has already been pre-populated for you.
In these cases, there is a flag set as `eval = FALSE`.
Make sure to remove this flag prior to running the relevant code chunk to avoid any errors when rendering the document.

# Exercises

## Exercise 0: Data Cleanup

We are going to do a preliminary cleaning step.
Let's drop any unused levels.

```{r}
#| label: load-data

loans_full_schema <- droplevels(loans_full_schema)
```

## Exercise 1: Train-Test Data Split

Split the data into a training and test set with a 75%-25% split.
Don't forget to set a seed!

```{r}
#| label: initial-split

set.seed(210)
loans_split <- initial_split(loans_full_schema)
loans_train <- training(loans_split)
loans_test <- testing(loans_split)
```

## Exercise 2: The Model

Write the model for predicting interest rate (`interest_rate`) from debt to income ratio (`debt_to_income`), the term of loan (`term`), the number of inquiries (credit checks) into the applicant's credit during the last 12 months (`inquiries_last_12m`), whether there are any bankruptcies listed in the public record for this applicant (`bankrupt`), and the type of application (`application_type`).
The model should allow for the effect of to income ratio on interest rate to vary by application type.

$$
\begin{aligned}
\widehat{\texttt{interest\_rate}} = b_0 &+ b_{DI}\cdot\texttt{debt\_to\_income} \\
&+ b_{term}\cdot\texttt{term} \\
&+ b_{CC}\cdot\texttt{inquiries\_last\_12m} \\ 
&+ b_{bank}\cdot\texttt{bankrupt} \\
&+ b_{app}\cdot\texttt{application\_type} \\
&+ b_{DI:app}\cdot\texttt{debt\_to\_income:application\_type}
\end{aligned}
$$

## Exercise 3: EDA

Explore characteristics of the variables you'll use for the model using the training data only.
Create both univariate and bivariate plots, and make sure to think about which plots are the most appropriate and effective given the data types.

Explore characteristics of the variables you'll use for the model using the training data only.
Create both univariate and bivariate plots, and make sure to think about which plots are the most appropriate and effective given the data types.

```{r}
#| label: explore
#| warning: false
#| message: false

ggplot(loans_train, aes(x = interest_rate)) +
  geom_histogram(bins = 20) +
  labs(
    x = "Interest Rate", y = "Count",
    title = "Distribution of Loan Interest Rates"
  )

ggplot(loans_train, aes(
  x = debt_to_income, y = interest_rate,
  color = application_type
)) +
  geom_point() +
  labs(
    x = "Debt-to-Income Ratio", y = "Interest Rate",
    title = "Interest Rate vs. Debt-to-Income, by App. Type"
  )

ggplot(loans_train, aes(
  x = as_factor(if_else(public_record_bankrupt == 0,
    "no", "yes"
  )),
  y = interest_rate
)) +
  geom_boxplot() +
  labs(
    x = "Past Bankrupcy Status", y = "Interest Rate",
    title = "Boxplots of Interest Rate by Bankruptcy Status"
  )
```

## Exercise 4: Model specification

Specify a linear regression model.
Call it `loans_spec`.

```{r}
#| label: specify-model

loans_spec <- linear_reg() %>%
  set_engine("lm")
```

## Exercise 5: Recipe building

-   Predict `interest_rate` from `debt_to_income`, `term`, `inquiries_last_12m`, `public_record_bankrupt`, and `application_type`.
-   Mean center `debt_to_income`.
-   Make `term` a factor.
-   Create a new variable: `bankrupt` that takes on the value "no" if `public_record_bankrupt` is 0 and the value "yes" if `public_record_bankrupt` is 1 or higher. Then, remove `public_record_bankrupt`.
-   Interact `application_type` with `debt_to_income`.
-   Create dummy variables where needed and drop any zero variance variables.

```{r}
#| label: create-recipe

loans_rec <- recipe(interest_rate ~ debt_to_income +
          term + inquiries_last_12m +
          public_record_bankrupt + application_type,
          data = loans_train) %>%
          step_center(debt_to_income) %>%
          step_mutate(term = as_factor(term)) %>%
          step_mutate(bankrupt = as_factor(if_else(public_record_bankrupt == 0, "no", "yes"))) %>%
          step_rm(public_record_bankrupt) %>%
          step_dummy(all_nominal_predictors()) %>%
          step_interact(terms = ~ starts_with("application_type"):debt_to_income) %>%
          step_zv(all_predictors())
```

## Exercise 6: Creating a workflow

Create the workflow that brings together the model specification and recipe.

```{r}
#| label: create-wflow

loans_wflow <- workflow() %>%
  add_model(loans_spec) %>%
  add_recipe(loans_rec)
```

## Exercise 7: Cross-validation and summary

Conduct 10-fold cross validation.

```{r}
#| label: cv-tenfold

set.seed(210)
loans_folds <- vfold_cv(loans_train, v = 10)
loans_fit_rs <- loans_wflow %>%
  fit_resamples(loans_folds)
loans_fit_rs
```

Summarize metrics from your CV resamples.

```{r}
#| label: cv-summarize

collect_metrics(loans_fit_rs)
```

# Writing Exercise

In this exercise, we will synthesize our work above to create a reader-friendly version of our conclusions.
In the classroom, these sorts of writing exercises appear throughout homework and lab assignments as well as exams.
They give students an opportunity to demonstrate their understanding while gaining an appreciation that communication is a crucial part of using statistics.

## Exploratory data analysis

Using your plots above (along with any other metrics you compute), describe your initial findings about the training data.
Discuss why we perform EDA only on the training data and not on the entire data set.

```{r}
loans_med <- median(loans_train$interest_rate)
loans_iqr <- IQR(loans_train$interest_rate)
```

It appears that the marginal distribution for interest rates is largely unimodal (possibly bimodal since there aren't many loans issued with interest rates around 7%) with a right-skew.
The median interest rate is `r loans_med` with IQR `r loans_iqr`.

It appears that there is no strong relationship between debt-to-income when the debt-to-income ratio is low.
It seems that the that joint applications generally have higher debt-to-income ratios, but possibly some lower interest rates for highly levered (i.e., high debt-to-income ratios, esepcially greater than 100%) applications.
These may be outliers.

The boxplot seems to suggest that while applications with a bankruptcy history have higher interest rates, the difference is very slight.

## Model fitting and fit evaluation

Although our primary aim is prediction and not inference, its good to check the model fit nonetheless to make sure nothing looks out of the ordinary.
Create a neatly organized table of the model output, and describe your observations, such as which parameters are significant.
Make sure to interpret some coefficients appropriately.

```{r}
loans_train_fit <- fit(loans_wflow, data = loans_train)
tidy(loans_train_fit) %>% 
  kable(digits = 2)
```

From the above table, it appears that all of the coefficients are significant at the 0.05 significance level except for \texttt{application\_type}.
However, the interaction with \texttt{debt\_to\_income} is significant, so we want to include the main effect.
We find that the sign of the coefficients is intuitive.
For instance, as the debt-to-income ratio increases by 1%, the interest rate is predicted to increase by about 0.11% on average, holding all equal.
Similarly, relative to loans with a 3-year maturity, loans with a 5-year maturity are predicted to have an interest rate about 3.84% higher on averaged, all else equal.

## Cross-validation

Explain what 10-fold CV does, and why it's useful.
Display a neat table with the outputs of your CV summary, and describe your observations.
Make sure to discuss why we are focusing on R-squared and RMSE instead of adjusted R-squared, AIC, and BIC.

10-fold CV splits the training data into roughly 10 equal groups, fits the model on 9 of the groups, and then tests the performance on the remaining 10th group.
This is done by leaving one group out at a team, and then averaging the error.
We do this because even though we cannot use the test data to in fitting the model, this allows us to get an idea of how well our model performs on data it has not seen before.
In turn, we can compare different models based on their predictive performance using metrics like R-squared and RMSE.
Since prediction is our primary concern, we use these metrics instead of R-squared, AIC, and BIC.

```{r}
cv_metrics <- collect_metrics(loans_fit_rs)
cv_metrics %>% 
  kable(digits=2)
loan_rmse <- cv_metrics$mean[1]
loan_rsq <- cv_metrics$mean[2]
```

The above table computes the RMSE, which is about `r round(loan_rmse, 2)`, and the R-squared, which is about `r round(loan_rsq, 2)`.
