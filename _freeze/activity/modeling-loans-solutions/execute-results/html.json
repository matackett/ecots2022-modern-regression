{
  "hash": "c1c0483aa19ab3e4dd302d3646f69da0",
  "result": {
    "markdown": "---\ntitle: \"Modeling loans - Solutions\"\nsubtitle: \"eCOTS 2022 - Modernizing the undergraduate regression analysis course\"\neditor: visual\nexecute:\n  freeze: auto\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(openintro)\n```\n:::\n\n\n# Introduction\n\nThe exercises below are drawn from an exam review.\nStudents would have already completed readings, some assignments, and labs prior to attempting these questions.\n\nYou may notice some code below has already been pre-populated for you.\nIn these cases, there is a flag set as `eval = FALSE`.\nMake sure to remove this flag prior to running the relevant code chunk to avoid any errors when rendering the document.\n\n## Data\n\nIn today's workshop, we will explore using the **tidymodels** framework for modeling along with the tidyverse framework for data wrangling and visualization.\nWe will start with some exploratory data analysis, walk through how to create the key components of a predictive model (models, recipes, and workflows), and how to perform cross-validation.\nThroughout we will be using the [`loans_full_schema`](http://openintrostat.github.io/openintro/reference/loans_full_schema.html) dataset from the **openintro** package[^1] and featured in the OpenIntro textbooks[^2]\n.\n\n[^1]: Mine Çetinkaya-Rundel, David Diez, Andrew Bray, Albert Y. Kim, Ben Baumer, Chester Ismay, Nick Paterno and Christopher Barr (2022).\n    openintro: Data Sets and Supplemental Functions from 'OpenIntro' Textbooks and Labs.\n    R package version 2.3.0.\n    <https://CRAN.R-project.org/package=openintro>.\n\n[^2]: Mine Çetinkaya-Rundel and Johanna Hardin.\n    2021.\n    OpenIntro::Introduction to Modern Statistics.\n    [https://openintro-ims.netlify.app](https://openintro-ims.netlify.app/).\n\nThe data has a bit of peculiarity about it, specifically the `application_type` variable is a factor variable with an empty level.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(loans_full_schema$application_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"\"           \"individual\" \"joint\"     \n```\n:::\n:::\n\n\nLet's clean up this variable using the `droplevels()` function first.\nAnd let's apply that to the whole dataset, in case there are other variables with similar issues.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_full_schema <- droplevels(loans_full_schema)\n```\n:::\n\n\nThe variables we'll use in this analysis are:\n\n-   `interest_rate`: Interest rate of the loan the applicant received.\n-   `debt_to_income`: Debt-to-income ratio.\n-   `term`: The number of months of the loan the applicant received.\n-   `inquiries_last_12m`: Inquiries into the applicant's credit during the last 12 months.\n-   `public_record_bankrupt`: Number of bankruptcies listed in the public record for this applicant.\n-   `application_type`: The type of application: either `individual` or `joint`.\n\n# Exercises\n\n## Exercise 1: Train-test data split\n\nSplit the data into a training and test set with a 75%-25% split.\nDon't forget to set a seed!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(210)\n\nloans_split <- initial_split(loans_full_schema)\nloans_train <- training(loans_split)\nloans_test <- testing(loans_split)\n```\n:::\n\n\n## Exercise 2: The Model\n\nWrite the model for predicting interest rate (`interest_rate`) from debt to income ratio (`debt_to_income`), the term of loan (`term`), the number of inquiries (credit checks) into the applicant's credit during the last 12 months (`inquiries_last_12m`), whether there are any bankruptcies listed in the public record for this applicant (`bankrupt`), and the type of application (`application_type`).\nThe model should allow for the effect of to income ratio on interest rate to vary by application type.\n\n\n$$\n\\begin{aligned}\n\\widehat{\\texttt{interest\\_rate}} = b_0 &+ b_1\\times\\texttt{debt\\_to\\_income} \\\\\n&+ b_2 \\times \\texttt{term} \\\\\n&+ b_3 \\times \\texttt{inquiries\\_last\\_12m} \\\\ \n&+ b_4 \\times \\texttt{bankrupt} \\\\\n&+ b_5 \\times \\texttt{application\\_type} \\\\\n&+ b_6 \\times \\texttt{debt\\_to\\_income:application\\_type}\n\\end{aligned}\n$$\n\n\n## Exercise 3: EDA\n\nExplore characteristics of the variables you'll use for the model using the training data only.\n\nFirst, take a peek at the relevant variables in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_train %>%\n  select(interest_rate, debt_to_income, term,\n         inquiries_last_12m, public_record_bankrupt, application_type) %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 7,500\nColumns: 6\n$ interest_rate          <dbl> 7.34, 21.85, 6.72, 17.47, 12.62, 7.34, 14.08, 1…\n$ debt_to_income         <dbl> 3.81, 32.80, 4.31, 8.94, 11.87, 4.51, 20.24, 9.…\n$ term                   <dbl> 36, 36, 36, 60, 60, 60, 60, 36, 60, 60, 36, 36,…\n$ inquiries_last_12m     <int> 0, 1, 2, 1, 0, 1, 3, 1, 0, 0, 0, 4, 0, 0, 0, 5,…\n$ public_record_bankrupt <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ application_type       <fct> individual, individual, individual, joint, indi…\n```\n:::\n:::\n\n\nCreate univariate, bivariate, and multivariate plots, and make sure to think about which plots are the most appropriate and effective given the data types.\n\n-   Interest rate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(loans_train, aes(x = interest_rate)) +\n  geom_histogram(binwidth = 1) +\n  labs(\n    x = \"Interest rate\", y = \"Count\",\n    title = \"Distribution of loan interest rates\"\n  )\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-interest-rate-1.png){fig-alt='A histogram of interest rate showing a right skewed distribution with peaks at 5%, 10%, and 15%. There are very few loans with interest rates above 20%.' width=672}\n:::\n:::\n\n\n-   Interest rate vs. debt to income ratio by application type:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(loans_train, \n       aes(x = debt_to_income, y = interest_rate,\n           color = application_type, shape = application_type)) +\n  geom_point() +\n  labs(\n    x = \"Debt-to-income ratio\", y = \"Interest rate\",\n    color = \"Application type\", shape = \"Application type\",\n    title = \"Interest rate vs. Debt-to-income by application type\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 16 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-debt-to-income-1.png){fig-alt='Scatterplot of interest rate vs. debt to income ratio, where different colors and shapes of point represent individual and joint applications. There is no clear relationship between interest rate and debt to income ratio. The only pattern that stands out is that debt to income ratio tends to be lower for individual applications (below 50) while it ranges all the way up to above 400 for joint applications.' width=672}\n:::\n:::\n\n\n-   Interest rate by bankruptcy:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_train %>%\n  mutate(bankrupt = if_else(public_record_bankrupt == 0, \"no\", \"yes\")) %>%\n  ggplot(aes(x = interest_rate, fill = bankrupt)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    x = \"Interest rate\", y = \"Density\",\n    fill = \"Past bankrupcy status\", \n    title = \"Interest rate by past bankruptcy status\"\n  )\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-bankrupt-1.png){fig-alt='Density plot of interest rate by past bankruptcy status. For applicants with and without past bankrupty interest rates have a right skewed distribution. Typical interest is higher for those with bankrupty and the distribution is unimodal, while it is bimodal for those without.' width=672}\n:::\n:::\n\n\n## Exercise 4: Model specification\n\nSpecify a linear regression model.\nCall it `loans_spec`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_spec <- linear_reg()\n```\n:::\n\n\n## Exercise 5: Recipe and formula building\n\n-   Predict `interest_rate` from `debt_to_income`, `term`, `inquiries_last_12m`, `public_record_bankrupt`, and `application_type`.\n-   Mean center `debt_to_income`.\n-   Make `term` a factor.\n-   Create a new variable: `bankrupt` that takes on the value \"no\" if `public_record_bankrupt` is 0 and the value \"yes\" if `public_record_bankrupt` is 1 or higher. Then, remove `public_record_bankrupt`.\n-   Interact `application_type` with `debt_to_income`.\n-   Create dummy variables where needed and drop any zero variance variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_rec <- recipe(interest_rate ~ debt_to_income +\n  term + inquiries_last_12m +\n  public_record_bankrupt + application_type,\ndata = loans_train\n) %>%\n  step_center(debt_to_income) %>%\n  step_mutate(term = as_factor(term)) %>%\n  step_mutate(bankrupt = as_factor(if_else(public_record_bankrupt == 0, \"no\", \"yes\"))) %>%\n  step_rm(public_record_bankrupt) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(terms = ~ starts_with(\"application_type\"):debt_to_income) %>%\n  step_zv(all_predictors())\n```\n:::\n\n\n## Exercise 6: Creating a workflow\n\nCreate the workflow that brings together the model specification and recipe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_wflow <- workflow() %>%\n  add_model(loans_spec) %>%\n  add_recipe(loans_rec)\n```\n:::\n\n\n## Exercise 7: Cross-validation and summary\n\nConduct 10-fold cross validation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(210)\nloans_folds <- vfold_cv(loans_train, v = 10)\nloans_fit_rs <- loans_wflow %>%\n  fit_resamples(loans_folds)\nloans_fit_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits             id     .metrics         .notes          \n   <list>             <chr>  <list>           <list>          \n 1 <split [6750/750]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]>\n 2 <split [6750/750]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]>\n 3 <split [6750/750]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]>\n 4 <split [6750/750]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]>\n 5 <split [6750/750]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]>\n 6 <split [6750/750]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]>\n 7 <split [6750/750]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]>\n 8 <split [6750/750]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]>\n 9 <split [6750/750]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]>\n10 <split [6750/750]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\nSummarize metrics from your CV resamples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(loans_fit_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   4.54     10 0.0363  Preprocessor1_Model1\n2 rsq     standard   0.173    10 0.00646 Preprocessor1_Model1\n```\n:::\n:::\n\n\nWe can also visualize the metrics across folds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(loans_fit_rs, summarize = FALSE) %>%\n  mutate(id = str_remove(id, \"Fold\")) %>%\n  ggplot(aes(x = id, y = .estimate, group = .metric)) +\n  geom_line() +\n  facet_wrap(~.metric, scales = \"free\", ncol = 1) +\n  labs(x = \"Fold\", y = \"Estimate\",\n       title = \"Cross-validation metrics\")\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/cv-visualize-1.png){fig-alt='Faceted line plot of cross-validation metrics. On top is RMSE and on the bottom is R-squared. The x-axis shows 10 folds and the y-axis shows the relevant metric estimate. R-squared values range from 15% to 21%. RMSE values range from roughly 4.4 to 4.75.' width=672}\n:::\n:::\n\n\n# Writing Exercise\n\nIn this exercise, we will synthesize our work above to create a reader-friendly version of our conclusions.\nIn the classroom, these sorts of writing exercises appear throughout homework and lab assignments as well as exams.\nThey give students an opportunity to demonstrate their understanding while gaining an appreciation that communication is a crucial part of using statistics.\n\n## Exploratory data analysis\n\nUsing your plots above (along with any other metrics you compute), describe your initial findings about the training data.\nDiscuss why we perform EDA only on the training data and not on the entire data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_med <- median(loans_train$interest_rate)\nloans_iqr <- IQR(loans_train$interest_rate)\n```\n:::\n\n\nIt appears that the marginal distribution for interest rates is largely unimodal (possibly bimodal since there aren't many loans issued with interest rates around 7%) with a right-skew.\nThe median interest rate is 11.98 with IQR 5.62.\n\nIt appears that there is no strong relationship between debt-to-income when the debt-to-income ratio is low.\nIt seems that the that joint applications generally have higher debt-to-income ratios, but possibly some lower interest rates for highly levered (i.e., high debt-to-income ratios, especially greater than 100%) applications.\nThese may be outliers.\n\nThe boxplot seems to suggest that while applications with a bankruptcy history have higher interest rates, the difference is very slight.\n\n## Model fitting and fit evaluation\n\nAlthough our primary aim is prediction and not inference, it may be of interest to view the model fit nonetheless to make sure nothing looks out of the ordinary.\nCreate a neatly organized table of the model output, and describe your observations, such as which parameters are significant.\nMake sure to interpret some coefficients appropriately.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_train_fit <- fit(loans_wflow, data = loans_train)\n\ntidy(loans_train_fit) %>% \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n|term                                    | estimate| std.error| statistic| p.value|\n|:---------------------------------------|--------:|---------:|---------:|-------:|\n|(Intercept)                             |    10.94|      0.08|    135.05|    0.00|\n|debt_to_income                          |     0.11|      0.01|     16.46|    0.00|\n|inquiries_last_12m                      |     0.22|      0.02|      9.91|    0.00|\n|term_X60                                |     3.84|      0.11|     33.41|    0.00|\n|application_type_joint                  |    -0.08|      0.16|     -0.53|    0.59|\n|bankrupt_yes                            |     0.46|      0.16|      2.84|    0.00|\n|application_type_joint_x_debt_to_income |    -0.09|      0.01|    -12.00|    0.00|\n:::\n:::\n\n\nFrom the above table, it appears that all of the coefficients are significant at the 0.05 significance level except for `application_type`.\nHowever, the interaction with `debt_to_income` is significant, so we want to include the main effect.\nWe find that the sign of the coefficients is intuitive.\nFor instance, as the debt-to-income ratio increases by 1%, the interest rate is predicted to increase by about 0.11% on average, holding all equal.\nSimilarly, relative to loans with a 3-year maturity, loans with a 5-year maturity are predicted to have an interest rate about 3.84% higher on averaged, all else equal.\n\n## Cross-validation\n\nExplain what 10-fold CV does, and why it's useful.\nDisplay a neat table with the outputs of your CV summary, and describe your observations.\nMake sure to discuss why we are focusing on R-squared and RMSE instead of adjusted R-squared, AIC, and BIC.\n\n10-fold CV splits the training data into roughly 10 equal groups, fits the model on 9 of the groups, and then tests the performance on the remaining 10th group.\nThis is done by leaving one group out at a team, and then averaging the error.\nWe do this because even though we cannot use the test data to in fitting the model, this allows us to get an idea of how well our model performs on data it has not seen before.\nIn turn, we can compare different models based on their predictive performance using metrics like R-squared and RMSE.\nSince prediction is our primary concern, we use these metrics instead of R-squared, AIC, and BIC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_metrics <- collect_metrics(loans_fit_rs)\ncv_metrics %>% kable(digits = 2)\n```\n\n::: {.cell-output-display}\n|.metric |.estimator | mean|  n| std_err|.config              |\n|:-------|:----------|----:|--:|-------:|:--------------------|\n|rmse    |standard   | 4.54| 10|    0.04|Preprocessor1_Model1 |\n|rsq     |standard   | 0.17| 10|    0.01|Preprocessor1_Model1 |\n:::\n\n```{.r .cell-code}\nloan_rmse <- cv_metrics$mean[1]\nloan_rsq <- cv_metrics$mean[2]\n```\n:::\n\n\nThe above table computes the RMSE, which is about 4.54, and the R-squared, which is about 0.17.\n",
    "supporting": [
      "modeling-loans-solutions_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}