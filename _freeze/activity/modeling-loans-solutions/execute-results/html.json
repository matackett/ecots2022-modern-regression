{
  "hash": "cfddfa5bcd66ebb71409363021760027",
  "result": {
    "markdown": "---\ntitle: \"Modeling loans - Solutions\"\nsubtitle: \"eCOTS 2022 - Modern Regression\"\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n# Demo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(openintro)\nlibrary(dplyr)\n```\n:::\n\n\n## Introduction\n\nIn today's workshop, we will explore how to use \\texttt{tidymodels} framework to perform data wrangling and modeling the data.\nWe will start with some exploratory data analysis (EDA), walk through how to create the key components of a predictive model (models, recipes, and workflows), and how to perform cross-validation.\nThroughout we will be using the \\texttt{loans} dataset from the OpenIntro textbook\\footnote{Diez, David M., Christopher D. Barr, and Mine Çetinkaya-Rundel. 2019. OpenIntro statistics.}\n\nThe exercises below are drawn from an exam review.\nStudents would have already completed readings, some assignments, and labs prior to attempting these questions.\n\nYou may notice some code below has already been pre-populated for you.\nIn these cases, there is a flag set as \\texttt{eval = FALSE}.\nMake sure to remove this flag prior to running the relevant code chunk to avoid any errors when rendering the pdf.\n\n## Exercise 0: Data Cleanup\n\nWe are going to do a preliminary cleaning step.\nLet's drop any unused levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(loans_full_schema)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config engineer \", \"warehouse…\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    <dbl> 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  <fct> Verified, Not Verified, Source Verifi…\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        <fct> , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66, NA, 13.12, NA,…\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               <int> 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            <int> 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     <int> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            <int> 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     <int> 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     <int> 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              <int> 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry <int> 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        <int> 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       <int> 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        <int> 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                <int> 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            <int> 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             <int> 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          <int> 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                <int> 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     <dbl> 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        <int> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     <fct> moving, debt_consolidation, other, de…\n$ application_type                 <fct> individual, individual, individual, i…\n$ loan_amount                      <int> 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      <dbl> 652.53, 167.54, 71.40, 664.19, 786.87…\n$ grade                            <fct> C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        <fct> C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      <fct> Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      <fct> Current, Current, Current, Current, C…\n$ initial_listing_status           <fct> whole, whole, fractional, whole, whol…\n$ disbursement_method              <fct> Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          <dbl> 27015.86, 4651.37, 1824.63, 18853.26,…\n$ paid_total                       <dbl> 1999.330, 499.120, 281.800, 3312.890,…\n$ paid_principal                   <dbl> 984.14, 348.63, 175.37, 2746.74, 1569…\n$ paid_interest                    <dbl> 1015.19, 150.49, 106.43, 566.15, 754.…\n$ paid_late_fees                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n```\n:::\n\n```{.r .cell-code}\nloans_full_schema <- droplevels(loans_full_schema)\n```\n:::\n\n\n## Exercise 1: Train-Test Data Split\n\nNow using \\texttt{tidymodels}, split the data into a training and test set with a 75%-25% split.\nDon't forget to set a seed!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(210)\nloans_split <- initial_split(loans_full_schema)\nloans_train <- training(loans_split)\nloans_test <- testing(loans_split)\n```\n:::\n\n\n## Exercise 2: The Model\n\nWrite the model for predicting interest rate (`interest_rate`) from debt to income ratio (`debt_to_income`), the term of loan (`term`), the number of inquiries (credit checks) into the applicant's credit during the last 12 months (`inquiries_last_12m`), whether there are any bankruptcies listed in the public record for this applicant (`bankrupt`), and the type of application (`application_type`).\nThe model should allow for the effect of to income ratio on interest rate to vary by application type.\n\n\n$$\n\\widehat{\\texttt{interest\\_rate}} = b_0 + b_{DI}\\cdot\\texttt{debt\\_to\\_income} + b_{term}\\cdot\\texttt{term} \\\\\n+ b_{CC}\\cdot\\texttt{inquiries\\_last\\_12m} + b_{bank}\\cdot\\texttt{bankrupt} \\\\\n+ b_{app}\\cdot\\texttt{application\\_type} + b_{DI:app}\\cdot\\text{debt\\_to\\_income:application\\_type}\n$$\n\n\n## Exercise 3: EDA\n\nExplore characteristics of the variables you'll use for the model using the training data only.\nCreate both univariate and bivariate plots, and make sure to think about which plots are the most appropriate and effective given the data types.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(loans_train, aes(x = interest_rate)) +\n  geom_histogram(bins = 20) +\n  labs(x = \"Interest Rate\", y = \"Count\",\n       title = \"Distribution of Loan Interest Rates\")\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-1.png){fig-align='center' width=480}\n:::\n\n```{.r .cell-code}\nggplot(loans_train, aes(x = debt_to_income, y = interest_rate,\n                        color = application_type)) +\n  geom_point() +\n  labs(x = \"Debt-to-Income Ratio\", y = \"Interest Rate\",\n       title = \"Interest Rate vs. Debt-to-Income, by App. Type\")\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-2.png){fig-align='center' width=480}\n:::\n\n```{.r .cell-code}\nggplot(loans_train, aes(x = as_factor(if_else(public_record_bankrupt == 0,\n                                              \"no\", \"yes\")),\n                        y = interest_rate)) + \n  geom_boxplot() +\n  labs(x = \"Past Bankrupcy Status\", y = \"Interest Rate\",\n       title = \"Boxplots of Interest Rate by Bankruptcy Status\")\n```\n\n::: {.cell-output-display}\n![](modeling-loans-solutions_files/figure-html/explore-3.png){fig-align='center' width=480}\n:::\n:::\n\n\n## Exercise 4: \\texttt{tidymodels} Model\n\nSpecify a linear regression model.\nCall it `loans_spec`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n```\n:::\n\n\n## Exercise 5: \\texttt{tidymodels} Recipe\n\n-   Predict `interest_rate` from `debt_to_income`, `term`, `inquiries_last_12m`, `public_record_bankrupt`, and `application_type`.\n-   Mean center `debt_to_income`.\n-   Make `term` a factor.\n-   Create a new variable: `bankrupt` that takes on the value \"no\" if `public_record_bankrupt` is 0 and the value \"yes\" if `public_record_bankrupt` is 1 or higher. Then, remove `public_record_bankrupt`.\n-   Interact `application_type` with `debt_to_income`.\n-   Create dummy variables where needed and drop any zero variance variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_rec <- recipe(interest_rate ~ debt_to_income +\n          term + inquiries_last_12m +\n          public_record_bankrupt + application_type,\n          data = loans_train) %>%\n          step_center(debt_to_income) %>%\n          step_mutate(term = as_factor(term)) %>%\n          step_mutate(bankrupt = as_factor(if_else(public_record_bankrupt == 0, \"no\", \"yes\"))) %>%\n          step_rm(public_record_bankrupt) %>%\n          step_dummy(all_nominal_predictors()) %>%\n          step_interact(terms = ~ starts_with(\"application_type\"):debt_to_income) %>%\n          step_zv(all_predictors())\n```\n:::\n\n\n## Exercise 6: \\texttt{tidymodels} Workflow\n\nCreate the workflow that brings together the model specification and recipe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_wflow <- workflow() %>%\n  add_model(loans_spec) %>%\n  add_recipe(loans_rec)\n```\n:::\n\n\n## Exercise 7: Cross-Validation and Summary\n\nConduct 10-fold cross validation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(210)\nloans_folds <- vfold_cv(loans_train, v = 10)\nloans_fit_rs <- loans_wflow %>%\n  fit_resamples(loans_folds)\nloans_fit_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits             id     .metrics         .notes          \n   <list>             <chr>  <list>           <list>          \n 1 <split [6750/750]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]>\n 2 <split [6750/750]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]>\n 3 <split [6750/750]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]>\n 4 <split [6750/750]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]>\n 5 <split [6750/750]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]>\n 6 <split [6750/750]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]>\n 7 <split [6750/750]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]>\n 8 <split [6750/750]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]>\n 9 <split [6750/750]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]>\n10 <split [6750/750]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\nSummarize metrics from your CV resamples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(loans_fit_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   4.54     10 0.0363  Preprocessor1_Model1\n2 rsq     standard   0.173    10 0.00646 Preprocessor1_Model1\n```\n:::\n:::\n\n\n# Writing Exercise\n\nIn this exercise, we will synthesize our work above to create a reader-friendly version of our conclusions.\nIn the classroom, these sorts of writing exercises appear throughout homework and lab assignments as well as exams.\nThey give students an opportunity to demonstrate their understanding while gaining an appreciation that communication is a crucial part of using statistics.\n\n## Exploratory Data Analysis\n\nUsing your plots above (along with any other metrics you compute), describe your initial findings about the training data.\nDiscuss why we perform EDA only on the training data and not on the entire data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_med <- median(loans_train$interest_rate)\nloans_iqr <- IQR(loans_train$interest_rate)\n```\n:::\n\n\nIt appears that the marginal distribution for interest rates is largely unimodal (possibly bimodal since there aren't many loans issued with interest rates around 7%) with a right-skew.\nThe median interest rate is 11.98 with IQR 5.62.\n\nIt appears that there is no strong relationship between debt-to-income when the debt-to-income ratio is low.\nIt seems that the that joint applications generally have higher debt-to-income ratios, but possibly some lower interest rates for highly levered (i.e., high debt-to-income ratios, esepcially greater than 100%) applications.\nThese may be outliers.\n\nThe boxplot seems to suggest that while applications with a bankruptcy history have higher interest rates, the difference is very slight.\n\n## Model and Model Fit\n\nAlthough our primary aim is prediction and not inference, its good to check the model fit nonetheless to make sure nothing looks out of the ordinary.\nCreate a neatly organized table of the model output, and describe your observations, such as which parameters are significant.\nMake sure to interpret some coefficients appropriately.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloans_train_fit <- fit(loans_wflow, data = loans_train)\ntidy(loans_train_fit) %>% \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n|term                                    | estimate| std.error| statistic| p.value|\n|:---------------------------------------|--------:|---------:|---------:|-------:|\n|(Intercept)                             |    10.94|      0.08|    135.05|    0.00|\n|debt_to_income                          |     0.11|      0.01|     16.46|    0.00|\n|inquiries_last_12m                      |     0.22|      0.02|      9.91|    0.00|\n|term_X60                                |     3.84|      0.11|     33.41|    0.00|\n|application_type_joint                  |    -0.08|      0.16|     -0.53|    0.59|\n|bankrupt_yes                            |     0.46|      0.16|      2.84|    0.00|\n|application_type_joint_x_debt_to_income |    -0.09|      0.01|    -12.00|    0.00|\n:::\n:::\n\n\nFrom the above table, it appears that all of the coefficients are significant at the 0.05 significance level except for \\texttt{application\\_type}.\nHowever, the interaction with \\texttt{debt\\_to\\_income} is significant, so we want to include the main effect.\nWe find that the sign of the coefficients is intuitive.\nFor instance, as the debt-to-income ratio increases by 1%, the interest rate is predicted to increase by about 0.11% on average, holding all equal.\nSimilarly, relative to loans with a 3-year maturity, loans with a 5-year maturity are predicted to have an interest rate about 3.84% higher on averaged, all else equal.\n\n## Cross-Validation\n\nExplain what 10-fold CV does, and why it's useful.\nDisplay a neat table with the outputs of your CV summary, and describe your observations.\nMake sure to discuss why we are focusing on R-squared and RMSE instead of adjusted R-squared, AIC, and BIC.\n\n10-fold CV splits the training data into roughly 10 equal groups, fits the model on 9 of the groups, and then tests the performance on the remaining 10th group.\nThis is done by leaving one group out at a team, and then averaging the error.\nWe do this because even though we cannot use the test data to in fitting the model, this allows us to get an idea of how well our model performs on data it has not seen before.\nIn turn, we can compare different models based on their predictive performance using metrics like R-squared and RMSE.\nSince prediction is our primary concern, we use these metrics instead of R-squared, AIC, and BIC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_metrics <- collect_metrics(loans_fit_rs)\ncv_metrics %>% \n  kable(digits=2)\n```\n\n::: {.cell-output-display}\n|.metric |.estimator | mean|  n| std_err|.config              |\n|:-------|:----------|----:|--:|-------:|:--------------------|\n|rmse    |standard   | 4.54| 10|    0.04|Preprocessor1_Model1 |\n|rsq     |standard   | 0.17| 10|    0.01|Preprocessor1_Model1 |\n:::\n\n```{.r .cell-code}\nloan_rmse <- cv_metrics$mean[1]\nloan_rsq <- cv_metrics$mean[2]\n```\n:::\n\n\nThe above table computes the RMSE, which is about 4.54, and the R-squared, which is about 0.17.\n",
    "supporting": [
      "modeling-loans-solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}